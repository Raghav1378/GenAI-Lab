{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf6b0c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91800\\Desktop\\GENAI UDEMY\\genai-udemy\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b223a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv \n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ff2f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.messages import BaseMessage, AIMessage\n",
    "from langchain_core.outputs import ChatResult, ChatGeneration\n",
    "from openai import OpenAI\n",
    "from typing import List, Optional, Any\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    ")\n",
    "\n",
    "class GroqChatModel(BaseChatModel):\n",
    "    model: str = \"openai/gpt-oss-20b\"\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,   # accept stop but ignore it\n",
    "        **kwargs: Any\n",
    "    ) -> ChatResult:\n",
    "\n",
    "        # Convert LangChain messages to plain prompt\n",
    "        prompt = \"\\n\".join([msg.content for msg in messages])\n",
    "\n",
    "        # Groq does NOT support stop sequences -> DO NOT PASS stop\n",
    "        response = client.responses.create(\n",
    "            model=self.model,\n",
    "            input=prompt,\n",
    "            max_output_tokens=300,\n",
    "            temperature=0.3\n",
    "        )\n",
    "\n",
    "        output_text = response.output_text\n",
    "\n",
    "        ai_msg = AIMessage(content=output_text)\n",
    "        generation = ChatGeneration(message=ai_msg)\n",
    "\n",
    "        return ChatResult(generations=[generation])\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"groq-chat-model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4627e05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GemmaRouter:\n",
    "    \"\"\"\n",
    "    A simple wrapper for using Google's Gemma-2-2B-IT model\n",
    "    via Hugging Face's OpenAI-compatible inference API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: str = \"google/gemma-2-2b-it:nebius\",\n",
    "        token_env: str = \"HF_THIRD_TOKEN\",\n",
    "        base_url: str = \"https://router.huggingface.co/v1\",\n",
    "    ):\n",
    "        api_key = os.getenv(token_env)\n",
    "        if not api_key:\n",
    "            raise ValueError(f\"Missing token: env variable '{token_env}' not found.\")\n",
    "\n",
    "        self.client = OpenAI(base_url=base_url, api_key=api_key)\n",
    "        self.model = model\n",
    "\n",
    "    def invoke(self, prompt: str, temperature: float = 0.7, max_tokens: int = 256):\n",
    "        \"\"\"Non-streaming response.\"\"\"\n",
    "        completion = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "        return completion.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "# Initialize Gemma model\n",
    "model = GemmaRouter()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41350adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e452ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_file = r\"C:\\Users\\91800\\Desktop\\GENAI UDEMY\\06-Level+1+Apps\\06-Level 1 Apps\\04-qa-from-sql\\data\\street_tree_db.sqlite\"\n",
    "\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{db_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7e74d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model3=ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21827e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many species of tree are in San Francisco?\n",
      "SQLQuery: SELECT count(DISTINCT \"qSpecies\") FROM street_trees\n"
     ]
    }
   ],
   "source": [
    "groq_llm = GroqChatModel()\n",
    "\n",
    "from langchain.chains import create_sql_query_chain\n",
    "\n",
    "chain = create_sql_query_chain(model3, db)\n",
    "\n",
    "response = chain.invoke({\"question\": \"How many species of tree are in San Francisco?\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a9c308d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many species of tree are in San Francisco?  \n",
      "SQLQuery:  \n",
      "```sql\n",
      "SELECT COUNT(DISTINCT \"qSpecies\") AS species_count\n",
      "FROM street_trees;\n",
      "```  \n",
      "SQLResult:  \n",
      "| species_count |\n",
      "|---------------|\n",
      "| 2             |  \n",
      "Answer: There are 2 distinct species of tree in San Francisco.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chain2 = create_sql_query_chain(groq_llm, db)\n",
    "response = chain2.invoke({\"question\": \"How many species of tree are in San Francisco?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7166bda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "sql_chain = create_sql_query_chain(\n",
    "    groq_llm,\n",
    "    db,\n",
    ")\n",
    "\n",
    "sql_chain = (\n",
    "    {\"question\": lambda x: x[\"question\"]}\n",
    "    | ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \n",
    "         \"You are an expert SQL generator. \"\n",
    "         \"ONLY return SQL. No explanations. No English. \"\n",
    "         \"No labels. No markdown.\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "    | sql_chain\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d72b807d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE street_trees (\n",
      "\t\"TreeID\" INTEGER, \n",
      "\t\"qLegalStatus\" TEXT, \n",
      "\t\"qSpecies\" TEXT, \n",
      "\t\"qAddress\" TEXT, \n",
      "\t\"SiteOrder\" REAL, \n",
      "\t\"qSiteInfo\" TEXT, \n",
      "\t\"PlantType\" TEXT, \n",
      "\t\"qCaretaker\" TEXT, \n",
      "\t\"qCareAssistant\" TEXT, \n",
      "\t\"PlantDate\" TEXT, \n",
      "\t\"DBH\" REAL, \n",
      "\t\"PlotSize\" TEXT, \n",
      "\t\"PermitNotes\" TEXT, \n",
      "\t\"XCoord\" REAL, \n",
      "\t\"YCoord\" REAL, \n",
      "\t\"Latitude\" REAL, \n",
      "\t\"Longitude\" REAL, \n",
      "\t\"Location\" TEXT, \n",
      "\t\"Fire Prevention Districts\" REAL, \n",
      "\t\"Police Districts\" REAL, \n",
      "\t\"Supervisor Districts\" REAL, \n",
      "\t\"Zip Codes\" REAL, \n",
      "\t\"Neighborhoods (old)\" REAL, \n",
      "\t\"Analysis Neighborhoods\" REAL\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from street_trees table:\n",
      "TreeID\tqLegalStatus\tqSpecies\tqAddress\tSiteOrder\tqSiteInfo\tPlantType\tqCaretaker\tqCareAssistant\tPlantDate\tDBH\tPlotSize\tPermitNotes\tXCoord\tYCoord\tLatitude\tLongitude\tLocation\tFire Prevention Districts\tPolice Districts\tSupervisor Districts\tZip Codes\tNeighborhoods (old)\tAnalysis Neighborhoods\n",
      "168225\tDPW Maintained\tArbutus 'Marina' :: Hybrid Strawberry Tree\t2547 Vallejo St\t1.0\tSidewalk: Curb side : Cutout\tTree\tPrivate\tNone\tNone\t0.0\tWidth 4ft\tNone\t6001190.70767\t2117587.71154\t37.794558498932695\t-122.43986908930565\t(37.794558498932695, -122.43986908930563)\t13.0\t9.0\t1.0\t57.0\t27.0\t30.0\n",
      "168228\tDPW Maintained\tArbutus 'Marina' :: Hybrid Strawberry Tree\t2547 Vallejo St\t4.0\tSidewalk: Curb side : Cutout\tTree\tPrivate\tNone\tNone\t0.0\tWidth 4ft\tNone\t6001242.69285\t2117592.6726\t37.79457507971764\t-122.43968957023225\t(37.79457507971764, -122.43968957023225)\t13.0\t9.0\t1.0\t57.0\t27.0\t30.0\n",
      "189160\tDPW Maintained\tAfrocarpus gracilior :: Fern Pine\t100 Kissling St\t3.0\t:\tTree\tPrivate\tNone\tNone\t2.0\tWidth 3ft\tNone\t6008158.83722\t2109400.58141\t37.77247279791805\t-122.41517858744544\t(37.77247279791805, -122.41517858744545)\t8.0\t2.0\t9.0\t28853.0\t19.0\t20.0\n",
      "*/\n"
     ]
    }
   ],
   "source": [
    "print(db.get_table_info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2d73aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-udemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
