{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a37b7daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91800\\Desktop\\GENAI UDEMY\\genai-udemy\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\91800\\Desktop\\GENAI UDEMY\\genai-udemy\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3699: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b023dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GemmaRouter:\n",
    "    \"\"\"\n",
    "    A simple wrapper for using Google's Gemma-2-2B-IT model\n",
    "    via Hugging Face's OpenAI-compatible inference API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: str = \"google/gemma-2-2b-it:nebius\",\n",
    "        token_env: str = \"HF_THIRD_TOKEN\",\n",
    "        base_url: str = \"https://router.huggingface.co/v1\",\n",
    "    ):\n",
    "        api_key = os.getenv(token_env)\n",
    "        if not api_key:\n",
    "            raise ValueError(f\"Missing token: env variable '{token_env}' not found.\")\n",
    "\n",
    "        self.client = OpenAI(base_url=base_url, api_key=api_key)\n",
    "        self.model = model\n",
    "\n",
    "    def invoke(self, prompt: str, temperature: float = 0.7, max_tokens: int = 256):\n",
    "        \"\"\"Non-streaming response.\"\"\"\n",
    "        completion = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "        return completion.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "# Initialize Gemma model\n",
    "model = GemmaRouter()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e43fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c0234ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Extract the following properties from the passage:\n",
    "\n",
    "- sentiment: The sentiment of the text\n",
    "- political_tendency: The political tendency of the user\n",
    "- language: The language the text is written in\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "\n",
    "Return your answer in plain text or JSON.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "class Classification(BaseModel):\n",
    "    sentiment: str = Field(description=\"The sentiment of the text\")\n",
    "    political_tendency: str = Field(description=\"The political tendency of the user\")\n",
    "    language: str = Field(description=\"The language the text is written in\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b713bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trump_follower = \"I'm confident that President Trump's leadership and track record will once again resonate with Americans. His strong stance on economic growth and national security is exactly what our country needs at this pivotal moment. We need to bring back the proven leadership that can make America great again!\"\n",
    "\n",
    "biden_follower = \"I believe President Biden's compassionate and steady approach is vital for our nation right now. His commitment to healthcare reform, climate change, and restoring our international alliances is crucial. It's time to continue the progress and ensure a future that benefits all Americans.But id d\"\n",
    "\n",
    "\n",
    "itachi_follower=\"People see only the mask I wear, but not the wars I fight within. My silence is mistaken for coldness, when it is simply the only place where my broken pieces donâ€™t tremble.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36b39313",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain2= tagging_prompt | model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "141454a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='```json\\n{\\n  \"sentiment\": \"Negative (sadness, vulnerability, loneliness)\",\\n  \"political_tendency\": \"Not applicable (no political content)\",\\n  \"language\": \"English\"\\n}\\n```', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--4421d2b4-fa0c-4a77-be5e-0ac5c8c929ef-0', usage_metadata={'input_tokens': 99, 'output_tokens': 47, 'total_tokens': 304, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2.invoke({\"input\":itachi_follower})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08fbece9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here\\'s the extracted information in JSON format:\\n\\n```json\\n{\\n  \"sentiment\": \"negative/emotional\",\\n  \"political_tendency\": \"neutral\",\\n  \"language\": \"English\"\\n}\\n```\\n\\nIn this passage, the sentiment is negative/emotional because the speaker mentions \\'wars I fight within\\' and \\'broken pieces,\\' indicating inner turmoil. They also express how their silence is misinterpreted, which adds to the emotional tone.\\n\\nAs for the political tendency, it is neutral. The passage does not convey any specific stance on politics or government, and the focus is on the speaker\\'s personal emotions and inner struggles.\\n\\nThe language is English, which is clearly indicated by the use of English words and grammar throughout the passage.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def groq_call(prompt):\n",
    "    response = groq_client.chat.completions.create(\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "model3 = RunnableLambda(groq_call)\n",
    "\n",
    "chain = (\n",
    "    tagging_prompt\n",
    "    | RunnableLambda(lambda x: x.to_string())   # FIX HERE\n",
    "    | model3\n",
    ")\n",
    "\n",
    "chain.invoke({\"input\": itachi_follower})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-udemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
