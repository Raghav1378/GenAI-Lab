{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8682d37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "load_dotenv()\n",
    "class GemmaRouter:\n",
    "    \"\"\"\n",
    "    A simple wrapper for using Google's Gemma-2-2B-IT model\n",
    "    via Hugging Face's OpenAI-compatible inference API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: str = \"google/gemma-2-2b-it:nebius\",\n",
    "        token_env: str = \"HF_THIRD_TOKEN\",\n",
    "        base_url: str = \"https://router.huggingface.co/v1\",\n",
    "    ):\n",
    "        load_dotenv()\n",
    "        api_key = os.getenv(token_env)\n",
    "        if not api_key:\n",
    "            raise ValueError(\n",
    "                f\"Missing token: environment variable '{token_env}' not found.\"\n",
    "            )\n",
    "\n",
    "        self.client = OpenAI(base_url=base_url, api_key=api_key)\n",
    "        self.model = model\n",
    "\n",
    "    def invoke(self, prompt: str, temperature: float = 0.7, max_tokens: int = 256):\n",
    "        \"\"\"Non-streaming response.\"\"\"\n",
    "        completion = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "        return completion.choices[0].message.content.strip()\n",
    "\n",
    "    def stream_invoke(self, prompt: str, temperature: float = 0.7, max_tokens: int = 256):\n",
    "        \"\"\"Streaming response.\"\"\"\n",
    "        stream = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "            stream=True,\n",
    "        )\n",
    "        return stream\n",
    "model2=GemmaRouter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baa28057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efccd836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The main cause that Itachi Uchiha had to commit the Uchiha Clan Massacre was a **tragic and impossible choice between the greater good of Konoha and the survival of his clan**, driven by his deep love for his village and, crucially, his profound desire to protect his younger brother, Sasuke.\\n\\nHere\\'s a breakdown of the complex factors:\\n\\n1.  **The Uchiha Coup d\\'Ã©tat:** The Uchiha clan, feeling marginalized and discriminated against by Konoha\\'s leadership (especially after being blamed for the Nine-Tails attack), was planning a full-scale coup to overthrow the village government. This would have inevitably led to a devastating civil war within Konoha.\\n\\n2.  **Itachi\\'s Loyalty to Konoha and Desire for Peace:** Itachi was a child prodigy who had witnessed the horrors of the Third Great Ninja War at a very young age. This experience instilled in him a profound desire for peace and a deep loyalty to Konoha as the entity that maintained that peace. He understood that a civil war would weaken the village, making it vulnerable to external attacks and causing immense suffering to countless innocent people.\\n\\n3.  **The Ultimatum from Konoha\\'s Elders:** The Konoha Elders (Hiruzen Sarutobi, Danzo Shimura, Koharu Utatane, and Homura Mitokado) discovered the Uchiha\\'s plans. They presented Itachi, who was already a double agent (spy for the Uchiha, but also a loyal ANBU for Konoha), with an impossible ultimatum: either allow the coup to proceed, leading to civil war and the potential destruction of Konoha and the Uchiha clan, or personally eliminate his clan to prevent the war, thus saving the village and, in their eyes, the Uchiha\\'s honor by preventing them from becoming traitors.\\n\\n4.  **Protection of Sasuke:** This was arguably the most personal and driving factor for Itachi. He loved his younger brother more than anything. He knew that if a civil war broke out, Sasuke would almost certainly die. By taking on the burden of the massacre himself, Itachi negotiated with the Elders to spare Sasuke\\'s life, ensuring his survival and giving him a future.\\n\\nIn essence, Itachi was forced into a situation where he had to choose the \"lesser of two evils.\" He chose to become the villain, sacrificing his own reputation, happiness, and future, to prevent a devastating war and protect the person he loved most. It was an act of extreme self-sacrifice born out of a grim sense of duty and love.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='lc_run--214bdeed-490e-4edb-9d46-33fbdf6e0955-0', usage_metadata={'input_tokens': 22, 'output_tokens': 531, 'total_tokens': 1548, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what is the main cause that you think that Itachi Uhciha had to commit such a crime \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a83673fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    name: Optional[str] = Field(default=None, description=\"The name of the person\")\n",
    "    lastname: Optional[str] = Field(\n",
    "        default=None, description=\"The lastname of the person if known\"\n",
    "    )\n",
    "    country: Optional[str] = Field(\n",
    "        default=None, description=\"The country of the person if known\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88e12a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert extraction algorithm. \"\n",
    "            \"Only extract relevant information from the text. \"\n",
    "            \"If you do not know the value of an attribute asked to extract, \"\n",
    "            \"return null for the attribute's value.\",\n",
    "        ),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6591e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model.with_structured_output(schema=Person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f04a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comment = \"I absolutely love this product! It's been a game-changer for my daily routine. The quality is top-notch and the customer service is outstanding. I've recommended it to all my friends and family. - Sarah Johnson, USA\"\n",
    "\n",
    "response = chain.invoke({\"text\": comment})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b71f429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Sarah' lastname='Johnson' country='USA'\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889eaeb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bappy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
